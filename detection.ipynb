{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from lesson_functions import *\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [400, 720]  # Min and max in y to search in slide_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "#glob.iglob('src/**/*.c', recursive=True)\n",
    "cars = glob.glob('./training_images/vehicles/**/*.png')\n",
    "notcars = glob.glob('./training_images/non-vehicles/**/*.png')\n",
    "print(len(cars))\n",
    "print(len(notcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training features\n",
    "t=time.time()\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to extract features...')\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Apply the scaler to X\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "print('train set size:', len(X_train))\n",
    "print('test set size:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(C=100, dual=False)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Training Accuracy of SVC = ', round(svc.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier(alpha= 1e-6,penalty='l2',loss='hinge',max_iter=1000,n_jobs=-1,tol=1e-7)\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SGD...')\n",
    "# Check the score of the SVC\n",
    "print('Training Accuracy of SGD = ', round(clf.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of SGD = ', round(clf.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 2,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'silent': 1,\n",
    "    'eta': 0.1,\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "plst = params.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "num_rounds = 40\n",
    "model = xgb.train(plst, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgbmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 10\n",
    "model = xgb.train(plst, dtrain, num_rounds, xgb_model='xgbmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.Booster(plst)\n",
    "model.load_model(\"xgbmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict\n",
    "dtest = xgb.DMatrix(X_train)\n",
    "ans = model.predict(dtest)\n",
    "\n",
    "# accuracy\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for i in range(len(y_train)):\n",
    "    if ans[i] == y_train[i]:\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "\n",
    "print(dtest.num_col())\n",
    "print(dtest.num_row())\n",
    "\n",
    "print(\"Training Accuracy: %.2f %% \" % (100 * cnt1 / (cnt1 + cnt2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对测试集进行预测\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "ans = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "for i in range(len(y_test)):\n",
    "    if ans[i] == y_test[i]:\n",
    "        cnt1 += 1\n",
    "    else:\n",
    "        cnt2 += 1\n",
    "\n",
    "print(dtest.num_col())\n",
    "print(dtest.num_row())\n",
    "print(\"Test Accuracy: %.2f %% \" % (100 * cnt1 / (cnt1 + cnt2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示重要特征\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# Use a linear SVC \n",
    "\n",
    "linear_svc=svm.SVC(C=100,gamma='auto',kernel='linear')\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "linear_svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train linear SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(linear_svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# Use a rbf SVC \n",
    "\n",
    "rbf_svc=svm.SVC(kernel='rbf',C=1e-3)\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "rbf_svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train rbf SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Training Accuracy of SVC = ', round(rbf_svc.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of SVC = ', round(rbf_svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the params\n",
    "data = {\n",
    "    'svc': svc,\n",
    "    'X_scaler': X_scaler\n",
    "}\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore params\n",
    "dist_pickle = pickle.load( open(\"16x16_data.pickle\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"X_scaler\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect\n",
    "y_start_stop = [400, 500]  # Min and max in y to search in slide_window()\n",
    "image = mpimg.imread('test_images/test6.jpg')\n",
    "draw_image = np.copy(image)\n",
    "\n",
    "image = image.astype('float32')/255\n",
    "\n",
    "# Uncomment the following line if you extracted training\n",
    "# data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "# image you are searching is a .jpg (scaled 0 to 255)\n",
    "#image = image.astype(np.float32)/255\n",
    "\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=y_start_stop, \n",
    "                    xy_window=(64, 64), xy_overlap=(0.75, 0.75))\n",
    "\n",
    "#print(len(windows))\n",
    "hot_windows = search_windows(image, windows, model, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "#print(len(hot_windows))\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "plt.imshow(window_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_image = np.copy(image)\n",
    "\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "add_heat(heat, hot_windows)\n",
    "# Apply threshold to help remove false positives\n",
    "heat = apply_threshold(heat, 1)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "labels = label(heatmap)\n",
    "    \n",
    "draw_labeled_bboxes(draw_image, labels)\n",
    "#plt.imshow(draw_image)\n",
    "#plt.show()\n",
    "\n",
    "figure, (detected_car_image_plot, detected_car_heatmap_plot, detected_car_labales_plot) = plt.subplots(1, 3, figsize=(20,15))\n",
    "        \n",
    "detected_car_image_plot.set_title('Detected cars')\n",
    "detected_car_image_plot.imshow(draw_image)\n",
    "\n",
    "detected_car_heatmap_plot.set_title('Heatmap')\n",
    "detected_car_heatmap_plot.imshow(heatmap)\n",
    "\n",
    "detected_car_labales_plot.set_title('Labels')\n",
    "detected_car_labales_plot.imshow(labels[0], cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    #draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255.0\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    #ctrans_tosearch = img_tosearch\n",
    "    #ctrans_tosearch = img\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    #print(nxsteps)\n",
    "    #print(nysteps)\n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    hot_windows = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))  \n",
    "            #test_prediction = svc.predict(test_features)\n",
    "            dtest = xgb.DMatrix(test_features)\n",
    "            test_prediction = model.predict(dtest)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "            #if test_decision > 0.7:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                hot_windows.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                #cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "    \n",
    "    #draw_labeled_bboxes(draw_img, labels)\n",
    "    \n",
    "    return hot_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_heat = []\n",
    "MAX_HISTORY = 10\n",
    "#history_heat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    hot_windows1 = []\n",
    "    hot_windows2 = []\n",
    "    hot_windows3 = []\n",
    "    hot_windows4 = []\n",
    "\n",
    "    hot_windows1 = find_cars(img, 400, 500, 1, model, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #hot_windows2 = find_cars(img, 380, 530, 1.1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    hot_windows2 = find_cars(img, 450, 530, 1.5, model, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    hot_windows3 = find_cars(img, 380, 530, 2, model, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "    #hot_windows1 = find_cars(img, 380, 530, 1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    #hot_windows2 = find_cars(img, 380, 550, 1.5, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    #hot_windows3 = find_cars(img, 380, 530, 2, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    #out_img,hot_windows1 = find_cars(img, 380, 530, 1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    #out_img,hot_windows1 = find_cars(img, 380, 530, 1, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    #plt.imshow(out_img)\n",
    "    #plt.show()\n",
    "    draw_img = np.copy(img)\n",
    "\n",
    "    hwin = hot_windows1 + hot_windows2 + hot_windows3\n",
    "    #hwin = hot_windows1\n",
    "\n",
    "\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    add_heat(heat, hwin)\n",
    "    #heat = apply_threshold(heat, 0)\n",
    "    heat = apply_threshold(heat, 2)\n",
    "\n",
    "\n",
    "    \n",
    "    if len(history_heat) < MAX_HISTORY:\n",
    "        history_heat.append(heat)\n",
    "    else:\n",
    "        del history_heat[0]\n",
    "        history_heat.append(heat)\n",
    "        \n",
    "\n",
    "    total_heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    for h in history_heat:\n",
    "        total_heat += h\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat_sum = apply_threshold(total_heat, 32)\n",
    "    #heat_sum = apply_threshold(total_heat, 2)\n",
    "\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat_sum, 0, 255)\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_labeled_bboxes(draw_img, labels)\n",
    "    \n",
    "    #plt.imshow(heat_sum, cmap='hot')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('./test_images/test3.jpg')\n",
    "out_img = pipeline(img)\n",
    "plt.imshow(out_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "def detectVideo(input_video,output):\n",
    "    clip1 = VideoFileClip(input_video)\n",
    "    out_clip = clip1.fl_image(pipeline)\n",
    "    out_clip.write_videofile(output,audio=False)\n",
    "\n",
    "#detectVideo('test_video.mp4','test_video_output.mp4')\n",
    "#project_video.mp4\n",
    "detectVideo('project_video.mp4','project_video_out.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "history_heat = []\n",
    "def clipVideo(input_video,output,start,end):\n",
    "    clip1 = VideoFileClip(input_video)\n",
    "    clip1 = clip1.subclip(start,end)\n",
    "    out_clip = clip1.fl_image(pipeline)\n",
    "    out_clip.write_videofile(output,audio=False)\n",
    "\n",
    "\n",
    "\n",
    "#clipVideo('test_video.mp4','test_video_clip.mp4',0,1)\n",
    "clipVideo('project_video.mp4','project_video_clip.mp4',44,47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
